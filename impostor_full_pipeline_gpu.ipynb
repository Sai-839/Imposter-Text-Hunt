{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68a395f",
   "metadata": {},
   "source": [
    "# Impostor Text Hunt - Hybrid Ensemble Pipeline\n",
    "\n",
    "This notebook implements a hybrid model combining classical ML features and a fine-tuned Transformer model for the task of detecting fake text. The notebook handles everything from preprocessing to prediction and submission file generation, with GPU support enabled where available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Install required packages (uncomment if running in a fresh Kaggle environment) (First Cell)\n",
    "#!pip install peft accelerate transformers datasets catboost xgboost scikit-learn nltk kaggle\n",
    "\n",
    "import os, re, string, nltk, random, torch, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Hugging Face & Sentence Transformers ---\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- Scikit-learn for Classical Models & Ensemble ---\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression # For Meta-Learner\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import scipy # For stats.uniform\n",
    "from google.colab import drive, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📥 NLTK DOWNLOADS\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab') # Not a standard NLTK download, might cause an error or warning\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# --- Suppress CatBoost verbose output during RandomizedSearchCV ---\n",
    "logging.getLogger('catboost').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfbcff-f09f-4285-899a-2919a0989448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# This line will block execution until you manually upload a file.\n",
    "# In a fully automated script, this needs to be removed or handled differently.\n",
    "uploaded = files.upload() # This will prompt a file selection dialog\n",
    "\n",
    "# Secure and move kaggle.json\n",
    "!mkdir -p ~/.kaggle/\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "print(\"Kaggle API key configured.\")\n",
    "\n",
    "# Download the competition data\n",
    "# Replace 'fake-or-real-the-impostor-hunt' with your competition slug if different\n",
    "KAGGLE_COMPETITION_SLUG = 'fake-or-real-the-impostor-hunt'\n",
    "!kaggle competitions download -c {KAGGLE_COMPETITION_SLUG}\n",
    "print(f\"Data for competition '{KAGGLE_COMPETITION_SLUG}' downloaded.\")\n",
    "\n",
    "# Unzip the downloaded data\n",
    "# IMPORTANT: Confirm the exact name of the downloaded .zip file. Use !ls if unsure.\n",
    "# The default output name is usually the competition slug + .zip\n",
    "DOWNLOADED_ZIP_FILE = f'{KAGGLE_COMPETITION_SLUG}.zip'\n",
    "EXTRACT_DIR = './data' # Directory to extract the data into\n",
    "\n",
    "print(f\"Unzipping {DOWNLOADED_ZIP_FILE} to {EXTRACT_DIR}...\")\n",
    "!mkdir -p {EXTRACT_DIR}\n",
    "!unzip {DOWNLOADED_ZIP_FILE} -d {EXTRACT_DIR} # This will prompt for overwrite if data exists\n",
    "print(\"Data unzipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5953f-959a-45cf-a9d5-f876f49526c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_DIR = \"./data/data\" # This assumes the zip extracts to 'data/data', verify this.\n",
    "                              # Often it extracts directly into 'data' so it might be './data'\n",
    "SEED = 42\n",
    "MODEL_NAME = 'distilbert-base-uncased' #Chosen smaller Transformer model\n",
    "NUM_FOLDS = 5 # For K-Fold Cross-Validation\n",
    "N_ITER_RANDOM_SEARCH = 10 # Number of iterations for RandomizedSearchCV\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 TEXT CLEANING FUNCTIONS\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower() # Ensure text is always string, handle potential None/NaN\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered = [lemmatizer.lemmatize(w) for w in tokens if w.isalpha() and w not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def extract_advanced_features(text_input): # Renamed to text_input to avoid confusion, though 'text' would be fine now.\n",
    "    text = str(text_input).strip() # Ensure text is string and strip whitespace\n",
    "    if not text: # Handle empty string case gracefully\n",
    "        # Return a list of zeros matching the number of features your col_names expect (9 features per text)\n",
    "        return [0.0] * 9 # Use float 0.0 to match potential numerical type\n",
    "\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    tokens = text.split() # Splits by whitespace\n",
    "\n",
    "    num_sentences = len([s for s in sentences if s.strip()]) # Count non-empty sentences\n",
    "    num_chars = len(text)\n",
    "    num_words = len(tokens)\n",
    "\n",
    "    # Handle cases where tokens might be empty to prevent division by zero\n",
    "    avg_word_len = np.mean([len(w) for w in tokens]) if tokens else 0.0\n",
    "    unique_tokens = set(t.lower() for t in tokens if t) # Ensure tokens are not empty for lower()\n",
    "    type_token_ratio = len(unique_tokens) / num_words if num_words else 0.0\n",
    "    uppercase_ratio = sum(1 for c in text if c.isupper()) / num_chars if num_chars > 0 else 0.0 # Handle num_chars == 0\n",
    "\n",
    "    punctuations = [',', '.', '?']\n",
    "    punct_counts = [text.count(p) for p in punctuations]\n",
    "\n",
    "    return [num_chars, num_words, avg_word_len, num_sentences, type_token_ratio, uppercase_ratio] + punct_counts\n",
    "\n",
    "# Corrected col_names generation: This needs to be defined AFTER extract_advanced_features\n",
    "feature_names = [\"len\", \"words\", \"avg_len\", \"sentences\", \"ttr\", \"upper_ratio\", \"comma\", \"period\", \"question\"]\n",
    "col_names = [f\"{name}{i}\" for i in (1, 2) for name in feature_names]\n",
    "# Verification of expected feature count: len(feature_names) should be 9\n",
    "print(f\"Expected number of features per text: {len(feature_names)}\") # Should be 9\n",
    "print(f\"Total columns expected for combined features: {len(col_names)}\") # Should be 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📚 Load and preprocess training data\n",
    "print(\"Loading and preparing training data...\")\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT_DIR, \"train\")\n",
    "\n",
    "# Now, you can correctly load train.csv\n",
    "try:\n",
    "    train_df_path = os.path.join(DATA_ROOT_DIR, \"train.csv\")\n",
    "    train_df = pd.read_csv(train_df_path)\n",
    "    print(f\"Successfully loaded train.csv from: {train_df_path}\")\n",
    "    print(\"\\nFirst 5 rows of train_df:\")\n",
    "    print(train_df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: train.csv not found at {train_df_path}. Please double-check the path after unzipping.\")\n",
    "    # Exit or raise error if train.csv is critical and not found\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading train.csv: {e}\")\n",
    "    raise\n",
    "\n",
    "# Create new columns in train_df to store raw texts and their cleaned versions for feature extraction\n",
    "all_raw1_loaded, all_raw2_loaded = [], []\n",
    "all_clean_texts_1_loaded, all_clean_texts_2_loaded = [], []\n",
    "all_features_loaded, all_labels_loaded = [], []\n",
    "loaded_ids = [] # Keep track of IDs for which files were successfully loaded\n",
    "\n",
    "print(\"Loading and processing training data (raw text, cleaned text, features)...\")\n",
    "for idx, real in tqdm(zip(train_df['id'], train_df['real_text_id']), total=len(train_df)):\n",
    "    article_path = os.path.join(TRAIN_DIR, f\"article_{str(idx).zfill(4)}\")\n",
    "    file1_path = os.path.join(article_path, \"file_1.txt\")\n",
    "    file2_path = os.path.join(article_path, \"file_2.txt\")\n",
    "\n",
    "    try:\n",
    "        with open(file1_path, 'r', encoding='utf-8') as f1:\n",
    "            raw1 = f1.read()\n",
    "        with open(file2_path, 'r', encoding='utf-8') as f2:\n",
    "            raw2 = f2.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File Not Found for article_{str(idx).zfill(4)} (files: {file1_path}, {file2_path}): Skipping.\")\n",
    "        continue\n",
    "    except Exception as e: # Catch other potential reading errors (e.g., encoding)\n",
    "        print(f\"Error reading files for article_{str(idx).zfill(4)}: {e}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Store raw texts\n",
    "    all_raw1_loaded.append(raw1)\n",
    "    all_raw2_loaded.append(raw2)\n",
    "\n",
    "    # Clean texts for classical features\n",
    "    clean1 = clean_text(raw1)\n",
    "    clean2 = clean_text(raw2)\n",
    "\n",
    "    all_clean_texts_1_loaded.append(clean1)\n",
    "    all_clean_texts_2_loaded.append(clean2)\n",
    "\n",
    "    all_features_loaded.append(extract_advanced_features(clean1) + extract_advanced_features(clean2))\n",
    "    # Label mapping: 'real_text_id' 1 typically means file_1 is real, 2 means file_2 is real.\n",
    "    # In binary classification for \"fake news detection\", you usually classify the *pair*\n",
    "    # as real (0) or fake (1).\n",
    "    # If real_text_id == 1 implies the pair is 'real', and real_text_id == 2 implies 'fake':\n",
    "    # This needs to be clarified based on the competition's exact target definition.\n",
    "    # Assuming `label = 0 if real == 1 else 1` means:\n",
    "    # if real_text_id is 1 (file_1 is real) -> label is 0 (real pair)\n",
    "    # if real_text_id is 2 (file_2 is real) -> label is 1 (fake pair, because the OTHER one is fake)\n",
    "    # This implies a target where 0 means \"text1 is real, text2 is fake\" and 1 means \"text2 is real, text1 is fake\"\n",
    "    # which is unusual for a single 'fake/real' classification of the *pair*.\n",
    "    # Re-verify your competition's target definition.\n",
    "    # For now, keeping your existing logic.\n",
    "    all_labels_loaded.append(0 if real == 1 else 1) # This determines your binary classification target\n",
    "    loaded_ids.append(idx)\n",
    "\n",
    "# Filter train_df to only include successfully loaded IDs\n",
    "train_df = train_df[train_df['id'].isin(loaded_ids)].reset_index(drop=True)\n",
    "\n",
    "# Add processed data as new columns to train_df\n",
    "train_df['raw_text_1'] = all_raw1_loaded\n",
    "train_df['raw_text_2'] = all_raw2_loaded\n",
    "train_df['clean_text_1'] = all_clean_texts_1_loaded # Keep for classical features\n",
    "train_df['clean_text_2'] = all_clean_texts_2_loaded # Keep for classical features\n",
    "\n",
    "# Add classical features to train_df\n",
    "# This line is now correct given the `extract_advanced_features` updates\n",
    "train_df[col_names] = pd.DataFrame(all_features_loaded, index=train_df.index)\n",
    "\n",
    "# Ensure the 'labels' used for classical models also aligns with the filtered train_df\n",
    "# Use the `labels` that were collected for the loaded_ids\n",
    "y_train_labels = pd.Series(all_labels_loaded, index=train_df.index)\n",
    "\n",
    "# Prepare features for classical models (X_train_features_df)\n",
    "# This part is redundant as features are already in train_df[col_names]\n",
    "X_train_features_df = train_df[col_names].copy()\n",
    "\n",
    "print(f\"Prepared {len(X_train_features_df)} samples for classical model training.\")\n",
    "print(\"Sample X_train_features_df head:\")\n",
    "print(X_train_features_df.head())\n",
    "print(\"Sample y_train_labels head:\")\n",
    "print(y_train_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72684c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🤖 Train all models \n",
    "# --- Transformer Model Loading (Done once) ---\n",
    "print(f\"Loading Transformer Model: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# Note: The actual model (sequence_model) will be loaded inside the K-fold loop\n",
    "# to ensure a fresh model for each fold or fine-tuned from base model.\n",
    "print(\"Transformer Tokenizer loaded.\")\n",
    "\n",
    "# --- K-Fold Cross-Validation Setup ---\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Lists to store out-of-fold predictions for meta-learner training\n",
    "# Initialize with np.float32 for consistency with model outputs if needed\n",
    "oof_classical_probs = np.zeros(len(X_train_features_df), dtype=np.float32)\n",
    "oof_transformer_probs = np.zeros(len(X_train_features_df), dtype=np.float32)\n",
    "oof_embedding_probs = np.zeros(len(X_train_features_df), dtype=np.float32)\n",
    "oof_true_labels = np.zeros(len(X_train_features_df), dtype=np.int32) # Labels are integers\n",
    "\n",
    "# Lists to store trained models for final test prediction (ensemble of ensembles)\n",
    "trained_voting_clfs = []\n",
    "trained_sequence_models = []\n",
    "trained_meta_learners = [] # This list will probably only have one meta-learner after training on all OOF\n",
    "trained_embedding_models = [] # Assuming embedding model is constant across folds\n",
    "\n",
    "print(f\"Starting {NUM_FOLDS}-Fold Cross-Validation...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_features_df, y_train_labels)):\n",
    "    print(f\"\\n--- Fold {fold + 1}/{NUM_FOLDS} ---\")\n",
    "\n",
    "    # --- Split Data for Current Fold ---\n",
    "    X_train_fold, X_val_fold = X_train_features_df.iloc[train_idx], X_train_features_df.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_labels.iloc[train_idx], y_train_labels.iloc[val_idx]\n",
    "\n",
    "    # Get raw texts for current fold's transformer/embedding training/validation\n",
    "    raw_text1_train_fold = train_df.iloc[train_idx]['raw_text_1'].tolist() # Use the new 'raw_text_1' column\n",
    "    raw_text2_train_fold = train_df.iloc[train_idx]['raw_text_2'].tolist() # Use the new 'raw_text_2' column\n",
    "    raw_text1_val_fold = train_df.iloc[val_idx]['raw_text_1'].tolist()\n",
    "    raw_text2_val_fold = train_df.iloc[val_idx]['raw_text_2'].tolist()\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # --- 1. Classical Models (VotingClassifier) Training & Tuning ---\n",
    "    # ---------------------------------------------------------------------\n",
    "    print(\"Training and tuning VotingClassifier...\")\n",
    "    estimators = [\n",
    "        ('rf', Pipeline([(\"scaler\", StandardScaler()), (\"model\", RandomForestClassifier(random_state=SEED, class_weight='balanced'))])),\n",
    "        ('gb', Pipeline([(\"scaler\", StandardScaler()), (\"model\", GradientBoostingClassifier(random_state=SEED))])),\n",
    "        ('svm', Pipeline([(\"scaler\", StandardScaler()), (\"model\", SVC(probability=True, class_weight='balanced', random_state=SEED))])),\n",
    "        ('xgb', Pipeline([(\"scaler\", StandardScaler()), (\"model\", XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=SEED))])),\n",
    "        ('cat', Pipeline([(\"scaler\", StandardScaler()), (\"model\", CatBoostClassifier(verbose=0, random_state=SEED))]))\n",
    "    ]\n",
    "\n",
    "    # Define parameter distributions for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'rf__model__n_estimators': scipy.stats.randint(50, 200),\n",
    "        'rf__model__max_depth': scipy.stats.randint(5, 20),\n",
    "        'gb__model__n_estimators': scipy.stats.randint(50, 200),\n",
    "        'gb__model__learning_rate': scipy.stats.uniform(0.01, 0.2),\n",
    "        'svm__model__C': scipy.stats.loguniform(0.1, 10),\n",
    "        'svm__model__gamma': scipy.stats.loguniform(0.001, 0.1),\n",
    "        'xgb__model__n_estimators': scipy.stats.randint(50, 200),\n",
    "        'xgb__model__learning_rate': scipy.stats.uniform(0.01, 0.2),\n",
    "        'cat__model__iterations': scipy.stats.randint(50, 200), # CatBoost uses 'iterations' not 'n_estimators'\n",
    "        'cat__model__learning_rate': scipy.stats.uniform(0.01, 0.2),\n",
    "        # Weights: Using dirichlet distribution to sample weights that sum to 1.\n",
    "        # This is a good way to explore the weight space.\n",
    "        'weights': [list(w) for w in np.random.dirichlet(np.ones(len(estimators)), size=N_ITER_RANDOM_SEARCH)]\n",
    "    }\n",
    "    # Create the VotingClassifier (without weights initially, as they are part of search)\n",
    "    voting_clf_base = VotingClassifier(estimators=estimators, voting='soft', verbose=False)\n",
    "\n",
    "    # Perform Randomized Search\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=voting_clf_base,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=N_ITER_RANDOM_SEARCH,\n",
    "        scoring='f1', # Use f1 for tuning\n",
    "        cv=3, # Mini-CV within each fold for tuning. Ensure this is <= size of train_fold\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1, # Use all available cores\n",
    "        verbose=0 # Set to 0 to suppress output\n",
    "    )\n",
    "    # The `fit` method of RandomizedSearchCV will fit the `best_estimator_`\n",
    "    random_search.fit(X_train_fold, y_train_fold)\n",
    "    best_voting_clf = random_search.best_estimator_\n",
    "    trained_voting_clfs.append(best_voting_clf) # Store the best fitted VotingClassifier\n",
    "\n",
    "    # Get OOF predictions for classical model\n",
    "    # Ensure X_val_fold is a DataFrame that best_voting_clf expects\n",
    "    oof_classical_probs[val_idx] = best_voting_clf.predict_proba(X_val_fold)[:, 1]\n",
    "    print(f\"Classical VotingClassifier F1 (Fold {fold+1}): {f1_score(y_val_fold, (oof_classical_probs[val_idx] > 0.5).astype(int)):.4f}\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # --- 2. Transformer Model Fine-tuning ---\n",
    "    # ---------------------------------------------------------------------\n",
    "    print(\"Fine-tuning Transformer model...\")\n",
    "    # Load a fresh model for each fold to avoid data leakage / sequential fine-tuning issues\n",
    "    sequence_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(device)\n",
    "\n",
    "    # Create datasets for the Trainer\n",
    "    class TextDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, texts1, texts2, labels, tokenizer):\n",
    "            # Pass lists directly to tokenizer for batch processing\n",
    "            self.encodings = tokenizer(texts1, texts2, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "            self.labels = torch.tensor(labels.tolist()) # Ensure labels are tensor\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "            item['labels'] = self.labels[idx]\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    train_dataset = TextDataset(raw_text1_train_fold, raw_text2_train_fold, y_train_fold, tokenizer)\n",
    "    val_dataset = TextDataset(raw_text1_val_fold, raw_text2_val_fold, y_val_fold, tokenizer)\n",
    "\n",
    "    # Training Arguments (can be tuned further, but keep 'report_to=\"none\"')\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./transformer_results_fold_{fold}\",\n",
    "        num_train_epochs=10, # Good starting point, Trainer's load_best_model_at_end handles early stopping implicitly\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True, # Will load the model with the best metric_for_best_model\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_steps=5,\n",
    "        seed=SEED,\n",
    "        save_total_limit=1, # Only save the best model to save disk space\n",
    "        learning_rate=2e-5,\n",
    "        warmup_ratio=0.06,\n",
    "        weight_decay=0.01,\n",
    "        fp16=True, # Uses mixed precision training if GPU is available\n",
    "        gradient_checkpointing=True, # Saves memory, slightly slower\n",
    "        report_to=\"none\", # Disable W&B\n",
    "        # greater_is_better=True is default for f1\n",
    "        # no_cuda=False # Not needed as 'device' handles this, and Trainer uses CUDA by default if available\n",
    "    )\n",
    "\n",
    "    # Define custom compute_metrics for Trainer\n",
    "    def compute_metrics(p):\n",
    "        preds = np.argmax(p.predictions, axis=1)\n",
    "        # Handle cases where there might be no positive samples in a fold's validation set\n",
    "        if np.sum(p.label_ids) == 0 and np.sum(preds) == 0:\n",
    "            f1 = 1.0 # Or nan, or 0.0 depending on how you want to handle it\n",
    "        else:\n",
    "            f1 = f1_score(p.label_ids, preds, average='binary', zero_division=0) # Use zero_division\n",
    "        acc = accuracy_score(p.label_ids, preds)\n",
    "        return {\"f1\": f1, \"accuracy\": acc}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=sequence_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Load the best model found by the Trainer\n",
    "    best_transformer_model_path = trainer.state.best_model_checkpoint\n",
    "    if best_transformer_model_path:\n",
    "        # Load the model from the best checkpoint\n",
    "        best_sequence_model_fold = AutoModelForSequenceClassification.from_pretrained(best_transformer_model_path).to(device)\n",
    "    else:\n",
    "        # Fallback if no best checkpoint saved (e.g., if training was too short, or metrics didn't improve)\n",
    "        # This will be the model at the last epoch.\n",
    "        print(f\"Warning: No best model checkpoint found for fold {fold+1}. Using the last trained model.\")\n",
    "        best_sequence_model_fold = sequence_model # Already on device from trainer init\n",
    "    trained_sequence_models.append(best_sequence_model_fold)\n",
    "\n",
    "    # Get OOF predictions for Transformer\n",
    "    # trainer.predict automatically uses the best model if load_best_model_at_end=True\n",
    "    val_preds_output = trainer.predict(val_dataset)\n",
    "    val_preds_logits = val_preds_output.predictions\n",
    "    oof_transformer_probs[val_idx] = torch.softmax(torch.tensor(val_preds_logits), dim=1)[:, 1].cpu().numpy()\n",
    "    print(f\"Transformer F1 (Fold {fold+1}): {f1_score(y_val_fold, (oof_transformer_probs[val_idx] > 0.5).astype(int), zero_division=0):.4f}\")\n",
    "\n",
    "    # Clear memory after each fold (important for GPU)\n",
    "    del trainer # This should deallocate most of the model memory\n",
    "    # Only delete sequence_model if you don't need it after appending to trained_sequence_models\n",
    "    # del sequence_model # The best_sequence_model_fold variable now holds the model\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # --- 3. Embedding-based Dissimilarity Calculation ---\n",
    "    # ---------------------------------------------------------------------\n",
    "    print(\"Calculating Embedding Dissimilarity...\")\n",
    "    # Load SentenceTransformer model once or inside loop if it needs re-initialization.\n",
    "    # It's more efficient to load it once globally if it's not being fine-tuned per fold.\n",
    "    # Moved embedding_model loading outside the fold loop to `main` or global scope.\n",
    "    if fold == 0: # Initialize/load embedding_model only once\n",
    "        try:\n",
    "            embedding_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "            trained_embedding_models.append(embedding_model) # Store the single instance\n",
    "            print(\"SentenceTransformer loaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading SentenceTransformer: {e}. Skipping embedding features for all folds.\")\n",
    "            embedding_model = None\n",
    "            trained_embedding_models.append(None) # Store None if it failed to load\n",
    "\n",
    "    # Retrieve the embedding model (could be None if loading failed)\n",
    "    current_embedding_model_for_fold = trained_embedding_models[0]\n",
    "\n",
    "    if current_embedding_model_for_fold:\n",
    "        current_embedding_model_for_fold.eval()\n",
    "        val_embedding_probs = []\n",
    "        # Process in batches to leverage GPU efficiently for SentenceTransformer\n",
    "        # You might want to define a `batch_size_st` for this\n",
    "        st_batch_size = 32 # Example batch size for SentenceTransformer\n",
    "        for i in tqdm(range(0, len(raw_text1_val_fold), st_batch_size), leave=False):\n",
    "            batch_raw1 = raw_text1_val_fold[i:i+st_batch_size]\n",
    "            batch_raw2 = raw_text2_val_fold[i:i+st_batch_size]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # encode returns tensors on the specified device\n",
    "                emb1_batch = current_embedding_model_for_fold.encode(batch_raw1, convert_to_tensor=True, device=str(device))\n",
    "                emb2_batch = current_embedding_model_for_fold.encode(batch_raw2, convert_to_tensor=True, device=str(device))\n",
    "\n",
    "                # Compute cosine similarity for the batch\n",
    "                # Use F.cosine_similarity for batch operations, or manual dot product and norm\n",
    "                # Manual: (emb1_batch * emb2_batch).sum(dim=1) / (torch.linalg.norm(emb1_batch, dim=1) * torch.linalg.norm(emb2_batch, dim=1) + epsilon)\n",
    "                # Simpler using util.cos_sim if sentence_transformers.util is imported\n",
    "                from sentence_transformers import util\n",
    "                cos_sim_batch = util.cos_sim(emb1_batch, emb2_batch).diagonal() # diagonal because it's pairwise between batch1 and batch2\n",
    "\n",
    "                val_embedding_probs.extend((1 - cos_sim_batch).cpu().numpy()) # Convert to numpy array\n",
    "\n",
    "        oof_embedding_probs[val_idx] = np.array(val_embedding_probs)\n",
    "        print(f\"Embedding F1 (Fold {fold+1}): {f1_score(y_val_fold, (oof_embedding_probs[val_idx] > 0.5).astype(int), zero_division=0):.4f}\")\n",
    "\n",
    "    else:\n",
    "        # If embedding model failed to load, fill with 0.5 (neutral)\n",
    "        oof_embedding_probs[val_idx] = np.full(len(val_idx), 0.5)\n",
    "        print(f\"Embedding model not loaded. Defaulting to 0.5 probability for fold {fold+1}.\")\n",
    "\n",
    "\n",
    "    # Store true labels for meta-learner training\n",
    "    oof_true_labels[val_idx] = y_val_fold.values\n",
    "\n",
    "# --- End of K-Fold Loop ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239713bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate OOF predictions to form meta-features\n",
    "print(\"\\n--- Training Meta-Learner ---\")\n",
    "meta_features = pd.DataFrame({\n",
    "    'classical_prob': oof_classical_probs,\n",
    "    'transformer_prob': oof_transformer_probs,\n",
    "    'embedding_prob': oof_embedding_probs\n",
    "})\n",
    "\n",
    "# Train the meta-learner on OOF predictions\n",
    "# The meta-learner is trained once on ALL OOF predictions, not per fold.\n",
    "# This is a standard stacking approach.\n",
    "meta_learner = LogisticRegression(random_state=SEED, solver='liblinear', C=0.1) # C can be tuned\n",
    "meta_learner.fit(meta_features, oof_true_labels)\n",
    "trained_meta_learners.append(meta_learner) # Store the single trained meta-learner\n",
    "print(\"Meta-Learner trained on OOF predictions.\")\n",
    "\n",
    "# Evaluate overall OOF ensemble performance\n",
    "oof_combined_preds = meta_learner.predict(meta_features)\n",
    "oof_final_f1 = f1_score(oof_true_labels, oof_combined_preds, average='binary', zero_division=0)\n",
    "oof_final_accuracy = accuracy_score(oof_true_labels, oof_combined_preds)\n",
    "print(f\"Overall OOF Meta-Learner F1: {oof_final_f1:.4f}\")\n",
    "print(f\"Overall OOF Meta-Learner Accuracy: {oof_final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f368d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 📤 FINAL TEST PREDICTION (Using the ensemble of trained models from each fold) ---\n",
    "print(\"\\n--- Starting Final Test Prediction ---\")\n",
    "TEST_DIR = os.path.join(DATA_ROOT_DIR, \"test\")\n",
    "# Ensure test_ids are from the main test directory\n",
    "test_ids = sorted([f for f in os.listdir(TEST_DIR) if os.path.isdir(os.path.join(TEST_DIR, f))])\n",
    "submission_rows = []\n",
    "\n",
    "# Collect all predictions for the test set from each fold's meta-learner.\n",
    "# Each element in this list will be a numpy array of predictions for the entire test set\n",
    "# from one fold's models.\n",
    "all_fold_meta_test_probs = []\n",
    "\n",
    "# Prepare the test data in a structured way to avoid re-reading files for each fold\n",
    "test_data_loaded = []\n",
    "print(\"Loading raw test data...\")\n",
    "for idx_dir in tqdm(test_ids):\n",
    "    try:\n",
    "        raw1_test = open(os.path.join(TEST_DIR, idx_dir, \"file_1.txt\"), 'r', encoding='utf-8').read()\n",
    "        raw2_test = open(os.path.join(TEST_DIR, idx_dir, \"file_2.txt\"), 'r', encoding='utf-8').read()\n",
    "        test_data_loaded.append({'id_dir': idx_dir, 'raw1': raw1_test, 'raw2': raw2_test})\n",
    "    except FileNotFoundError:\n",
    "        print(f'File Not Found for {idx_dir} in test set. Skipping this entry.')\n",
    "        # You might need a strategy to handle missing test files for submission (e.g., predict default)\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading test files for {idx_dir}: {e}. Skipping.\")\n",
    "        continue\n",
    "print(f\"Loaded {len(test_data_loaded)} test file pairs.\")\n",
    "\n",
    "\n",
    "for fold_num in range(NUM_FOLDS):\n",
    "    print(f\"Making predictions with Fold {fold_num + 1} models...\")\n",
    "    current_voting_clf = trained_voting_clfs[fold_num]\n",
    "    current_sequence_model = trained_sequence_models[fold_num]\n",
    "    current_meta_learner = trained_meta_learners[0] # The single meta-learner trained on OOF\n",
    "    current_embedding_model = trained_embedding_models[0] # The single loaded embedding model\n",
    "\n",
    "    fold_test_meta_features = []\n",
    "\n",
    "    # Ensure models are in evaluation mode\n",
    "    current_sequence_model.eval()\n",
    "    if current_embedding_model:\n",
    "        current_embedding_model.eval()\n",
    "\n",
    "    # Process test data for the current fold's ensemble\n",
    "    test_ids_for_fold_preds = [] # To keep track of IDs predicted in this fold\n",
    "    for entry in tqdm(test_data_loaded, leave=False):\n",
    "        idx_dir = entry['id_dir']\n",
    "        raw1 = entry['raw1']\n",
    "        raw2 = entry['raw2']\n",
    "\n",
    "        clean1 = clean_text(raw1)\n",
    "        clean2 = clean_text(raw2)\n",
    "\n",
    "        # --- Classical Features Prediction ---\n",
    "        features = extract_advanced_features(clean1) + extract_advanced_features(clean2)\n",
    "        features_df = pd.DataFrame([features], columns=col_names)\n",
    "        classical_prob = current_voting_clf.predict_proba(features_df)[0][1]\n",
    "\n",
    "        # --- Transformer Prediction ---\n",
    "        # Note: If batching is desired for transformer test predictions, collect inputs and predict in batches\n",
    "        inputs = tokenizer(raw1, raw2, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            logits = current_sequence_model(**inputs).logits\n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        transformer_prob = probs[0, 1]\n",
    "\n",
    "        # --- Embedding-based Dissimilarity Calculation ---\n",
    "        embedding_prob = 0.5 # Default if embedding_model failed to load\n",
    "        if current_embedding_model:\n",
    "            with torch.no_grad():\n",
    "                emb1 = current_embedding_model.encode(raw1, convert_to_tensor=True, device=str(device))\n",
    "                emb2 = current_embedding_model.encode(raw2, convert_to_tensor=True, device=str(device))\n",
    "                epsilon = 1e-8\n",
    "                cos_sim_tensor = torch.dot(emb1, emb2) / \\\n",
    "                                 (torch.linalg.norm(emb1) * torch.linalg.norm(emb2) + epsilon)\n",
    "                embedding_prob = 1 - cos_sim_tensor.item()\n",
    "\n",
    "        fold_test_meta_features.append([classical_prob, transformer_prob, embedding_prob])\n",
    "        test_ids_for_fold_preds.append(idx_dir) # Track IDs for this fold's predictions\n",
    "\n",
    "    # Convert to DataFrame for meta-learner prediction\n",
    "    # Ensure the columns match what the meta_learner was trained on\n",
    "    fold_meta_df = pd.DataFrame(fold_test_meta_features, columns=['classical_prob', 'transformer_prob', 'embedding_prob'])\n",
    "    fold_meta_probs = current_meta_learner.predict_proba(fold_meta_df)[:, 1]\n",
    "    all_fold_meta_test_probs.append(fold_meta_probs) # Store this fold's predictions\n",
    "\n",
    "# Average predictions from all folds' meta-learners\n",
    "# This averages probabilities across folds for each test sample.\n",
    "# Ensure that all_fold_meta_test_probs contains arrays of the same length and order.\n",
    "if all_fold_meta_test_probs:\n",
    "    final_test_meta_probs_avg = np.mean(all_fold_meta_test_probs, axis=0)\n",
    "else:\n",
    "    print(\"Warning: No test predictions generated by any fold.\")\n",
    "    final_test_meta_probs_avg = np.zeros(len(test_data_loaded)) # Fallback to zeros\n",
    "\n",
    "\n",
    "# Create submission file (using the averaged predictions and the initially loaded test_data_loaded)\n",
    "# The order of `test_data_loaded` and `final_test_meta_probs_avg` should match.\n",
    "for i, entry in enumerate(test_data_loaded):\n",
    "    idx_dir = entry['id_dir']\n",
    "    idx_number = int(idx_dir.split('_')[-1])\n",
    "    final_prob = final_test_meta_probs_avg[i] # Get the final probability for this sample\n",
    "\n",
    "    # Determine real_text_id based on your competition rules.\n",
    "    # Reconfirm your mapping for real_text_id. Assuming:\n",
    "    # if final_prob > 0.5, it's a \"fake news\" pair (Class 1).\n",
    "    # If competition asks for `real_text_id`:\n",
    "    # 1: file_1.txt is real (implies file_2.txt is fake, so the *pair* is fake)\n",
    "    # 2: file_2.txt is real (implies file_1.txt is fake, so the *pair* is fake)\n",
    "    # This mapping is still ambiguous. Let's assume your original `y_train_labels` logic:\n",
    "    # `0 if real == 1 else 1` means:\n",
    "    # 0 -> real_text_id was 1 (file_1 is real)\n",
    "    # 1 -> real_text_id was 2 (file_2 is real)\n",
    "    # So if your model predicts `1` (higher probability), it corresponds to `real_text_id=2`.\n",
    "    # If your model predicts `0` (lower probability), it corresponds to `real_text_id=1`.\n",
    "    real_text_id = 2 if final_prob > 0.5 else 1 # THIS IS A CRITICAL MAPPING, VERIFY WITH COMPETITION\n",
    "\n",
    "    submission_rows.append({\"id\": idx_number, \"real_text_id\": real_text_id})\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "submission_df.sort_values(\"id\", inplace=True)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ submission.csv generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
